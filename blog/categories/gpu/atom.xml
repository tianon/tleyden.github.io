<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: gpu | Seven Story Rabbit Hole]]></title>
  <link href="http://tleyden.github.io/blog/categories/gpu/atom.xml" rel="self"/>
  <link href="http://tleyden.github.io/"/>
  <updated>2014-12-02T08:10:24-08:00</updated>
  <id>http://tleyden.github.io/</id>
  <author>
    <name><![CDATA[Traun Leyden]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CoreOS with Nvidia CUDA GPU drivers]]></title>
    <link href="http://tleyden.github.io/blog/2014/11/04/coreos-with-nvidia-cuda-gpu-drivers/"/>
    <updated>2014-11-04T07:08:00-08:00</updated>
    <id>http://tleyden.github.io/blog/2014/11/04/coreos-with-nvidia-cuda-gpu-drivers</id>
    <content type="html"><![CDATA[<p>This will walk you through installing the Nvidia GPU kernel module and CUDA drivers on a docker container running inside of CoreOS.</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/coreos-nvidia-gpu.png" alt="architecture diagram" /></p>

<h2>Launch CoreOS on an AWS GPU instance</h2>

<ul>
<li><p>Launch a new EC2 instance</p></li>
<li><p>Under &ldquo;Community AMIs&rdquo;, search for <strong>ami-7c8b3f14</strong> (CoreOS-stable-410.1.0-hvm)</p></li>
<li><p>Select the GPU instances: <strong>g2.2xlarge</strong></p></li>
<li><p>Increase root EBS store from 8 GB &ndash;> 20 GB to give yourself some breathing room</p></li>
</ul>


<h2>ssh into CoreOS instance</h2>

<p>Find the public ip of the EC2 instance launched above, and ssh into it:</p>

<p><code>
$ ssh -A core@ec2-54-80-24-46.compute-1.amazonaws.com
</code></p>

<h2>Run Ubuntu 12 docker container in privileged mode</h2>

<p><code>
$ sudo docker run --privileged=true -i -t ubuntu:12.04 /bin/bash
</code></p>

<p>After the above command, you should be inside a root shell in your docker container.  The rest of the steps will assume this.</p>

<h2>Install build tools + other required packages</h2>

<p><code>
$ apt-get update
$ apt-get install build-essential wget git
</code></p>

<h2>Prepare CoreOS kernel source</h2>

<p><strong>Clone CoreOS kernel repository</strong></p>

<p><code>
$ mkdir -p /usr/src/kernels
$ cd /usr/src/kernels
$ git clone https://github.com/coreos/linux.git
</code></p>

<p><strong>Get CoreOS kernel version</strong></p>

<p><code>
$ uname -a
Linux ip-10-183-54-167.ec2.internal 3.15.8+ #2 SMP Fri Sep 26 08:37:17 UTC 2014 x86_64 Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz GenuineIntel GNU/Linux
</code></p>

<p>The CoreOS kernel version is <strong>3.15.8</strong></p>

<p><strong>Switch correct branch for this kernel version </strong></p>

<p><code>
$ cd linux
$ git checkout remotes/origin/coreos/v3.15.8
</code></p>

<p><strong>Create kernel configuration file</strong></p>

<p><code>
$ zcat /proc/config.gz &gt; /usr/src/kernels/linux/.config
</code></p>

<p><strong>Prepare kernel source for building modules</strong></p>

<p><code>
$ cd /usr/src/kernels/linux
$ make modules_prepare
</code></p>

<p>Now you should be ready to install the nvidia driver.</p>

<h2>Install nvidia driver</h2>

<p><strong>Download</strong></p>

<p><code>
$ mkdir -p /opt/nvidia
$ cd /opt/nvidia
$ wget http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run
</code></p>

<p><strong>Unpack</strong></p>

<p><code>
$ chmod +x cuda_6.5.14_linux_64.run
$ mkdir nvidia_installers
$ ./cuda_6.5.14_linux_64.run -extract=`pwd`/nvidia_installers
</code></p>

<p><strong>Install</strong></p>

<p><code>
$ cd nvidia_installers
$ ./NVIDIA-Linux-x86_64-340.29.run --kernel-source-path=/usr/src/kernels/linux/
</code></p>

<p><strong>Installer Questions</strong></p>

<ul>
<li>Install NVidia&rsquo;s 32-bit compatibility libraries? <strong>YES</strong></li>
<li>Would you like to run nvidia-xconfig? <strong>NO</strong></li>
</ul>


<p>If everything worked, you should see:</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/nvidia_driver_installed.png" alt="nvidia drivers installed" /></p>

<h2>Load nvidia kernel module</h2>

<p><code>
$ modprobe nvidia
</code></p>

<p>No errors should be returned.  Verify it&rsquo;s loaded by running:</p>

<p><code>
$ lsmod | grep -i nvidia
</code></p>

<p>and you should see:</p>

<p><code>
nvidia              10533711  0
i2c_core               41189  2 nvidia,i2c_piix4
</code></p>

<h2>Install CUDA</h2>

<p><code>
$ ./cuda-linux64-rel-6.5.14-18749181.run
$ ./cuda-samples-linux-6.5.14-18745345.run
</code></p>

<h2>Verify CUDA</h2>

<p><code>
$ cd /usr/local/cuda/samples/1_Utilities/deviceQuery
$ make
$ ./deviceQuery   
</code></p>

<p>You should see the following output:</p>

<p><code>
deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 6.5, CUDA Runtime Version = 6.5, NumDevs = 1, Device0 = GRID K520
Result = PASS
</code></p>

<p>Congratulations!  You now have a docker container running under CoreOS that can access the GPU.</p>

<h1>Appendix A: Using Core OS Alpha</h1>

<p>The instructions above were for an older version of CoreOS.  The following instructions are for Core OS Alpha, and might possibly work on the current version of CoreOS stable (444.5.0).  Only the parts that differ from above steps are listed:</p>

<h2>Launch CoreOS Alpha on an AWS GPU instance</h2>

<ul>
<li>Under &ldquo;Community AMIs&rdquo;, search for <strong>ami-66e6680e</strong> (CoreOS-alpha-490.0.0-hvm)</li>
</ul>


<h2>Run Ubuntu 14 docker container in privileged mode</h2>

<p><code>
$ sudo docker run --privileged=true -i -t ubuntu:14.04 /bin/bash
</code></p>

<p>After the above command, you should be inside a root shell in your docker container.  The rest of the steps will assume this.</p>

<h2>Install build tools + other required packages</h2>

<p>In order to match the version of gcc that was used to build the CoreOS kernel.  (gcc 4.7)</p>

<p><code>
$ apt-get update
$ apt-get install gcc-4.7 g++-4.7 wget git make dpkg-dev
</code></p>

<p><strong>Set gcc 4.7 as default</strong></p>

<p><code>
$ update-alternatives --remove gcc /usr/bin/gcc-4.8
$ update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.7 60 --slave /usr/bin/g++ g++ /usr/bin/g++-4.7
$ update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 40 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8
</code></p>

<p><strong>Verify</strong></p>

<p><code>
$ update-alternatives --config gcc
</code></p>

<p>It should list gcc 4.7 with an asterisk next to it:</p>

<p><code>
* 0            /usr/bin/gcc-4.7   60        auto mode
</code></p>

<h2>Prepare CoreOS kernel source</h2>

<p><strong>Get CoreOS kernel version</strong></p>

<p><code>
$ uname -a
Linux ip-10-11-167-200.ec2.internal 3.17.2+ #2 SMP Tue Nov 4 04:15:48 UTC 2014 x86_64 Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz GenuineIntel GNU/Linux
</code></p>

<p>The CoreOS kernel version is <strong>3.17.2</strong></p>

<p><strong>Switch correct branch for this kernel version </strong></p>

<p><code>
$ cd linux
$ git checkout remotes/origin/coreos/v3.17.2
</code></p>

<h1>Appendix B: Expose GPU to other docker containers</h1>

<p>If you need <em>other</em> docker containers on this CoreOS instance to be able to access the GPU, you can do the following steps.</p>

<p><em>Note:</em> you need to be using CoreOS-alpha-490.0.0 or later, since this requires Docker 1.3 to work.</p>

<p><strong>Exit docker container</strong></p>

<p><code>
$ exit
</code></p>

<p>You should be back to your CoreOS shell.</p>

<p><strong>Add nvidia device nodes</strong></p>

<p><code>
$ wget https://gist.githubusercontent.com/tleyden/74f593a0beea300de08c/raw/95ed93c5751a989e58153db6f88c35515b7af120/nvidia_devices.sh
$ chmod +x nvida_devices.sh
$ sudo ./nvida_devices.sh
</code></p>

<p><strong>Verify device nodes</strong></p>

<p><code>
$ ls -alh /dev | grep -i nvidia
crw-rw-rw-  1 root root  251,   0 Nov  5 16:37 nvidia-uvm
crw-rw-rw-  1 root root  195,   0 Nov  5 16:37 nvidia0
crw-rw-rw-  1 root root  195, 255 Nov  5 16:37 nvidiactl
</code></p>

<p><strong>Launch docker containers</strong></p>

<p>When you launch other docker containers on the same CoreOS instance, to allow them to access the GPU device you will need to add the following arguments:</p>

<p><code>
$ sudo docker run -ti --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm tleyden5iwx/ubuntu-cuda /bin/bash
</code></p>

<p>A complete example is available in <a href="http://tleyden.github.io/blog/2014/10/25/docker-on-aws-gpu-ubuntu-14-dot-04-slash-cuda-6-dot-5/">Docker on AWS GPU Ubuntu 14.04 / CUDA 6.5</a>.  You can pick up at th <strong>Run GPU enabled docker image</strong> step.</p>

<h2>References</h2>

<ul>
<li><a href="https://groups.google.com/forum/#!topic/coreos-user/CSp_wSywmI4">https://groups.google.com/forum/#!topic/coreos-user/CSp_wSywmI4</a> &ndash; Thanks Сергей!</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Caffe on AWS GPU instance via Docker]]></title>
    <link href="http://tleyden.github.io/blog/2014/10/25/running-caffe-on-aws-gpu-instance-via-docker/"/>
    <updated>2014-10-25T20:42:00-07:00</updated>
    <id>http://tleyden.github.io/blog/2014/10/25/running-caffe-on-aws-gpu-instance-via-docker</id>
    <content type="html"><![CDATA[<p>This is a tutorial to help you get the <a href="http://caffe.berkeleyvision.org/">Caffe deep learning framework</a> up and running on a GPU-powered AWS instance running inside a Docker container.</p>

<h2>Architecture</h2>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/caffe_docker_aws_onion.png" alt="architecture diagram" /></p>

<h2>Setup host</h2>

<p>Before you can start your docker container, you will need to go <strong>deeper down the rabbit hole</strong>.</p>

<p>You&rsquo;ll first need to complete the steps here:</p>

<p><a href="http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/">Setting up an Ubuntu 14.04 box running on a GPU-enabled AWS instance</a></p>

<p>After you&rsquo;re done, you&rsquo;ll end up with a host OS with the following properties:</p>

<ul>
<li>A GPU enabled AWS instance running Ubuntu 14.04</li>
<li>Nvidia kernel module</li>
<li>Nvidia device drivers</li>
<li>CUDA 6.5 installed and verified</li>
</ul>


<h2>Install Docker</h2>

<p>Once your host OS is setup, you&rsquo;re ready to install docker.  (version 1.3 at the time of this writing)</p>

<p>Setup the key for the docker repo:</p>

<p><code>
$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9
</code></p>

<p>Add the docker repo:</p>

<p><code>
$ sudo sh -c "echo deb https://get.docker.com/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list"
$ sudo apt-get update
</code></p>

<p>Install docker:</p>

<p><code>
$ sudo apt-get install lxc-docker
</code></p>

<h2>Run the docker container</h2>

<p><strong>Find your nvidia devices</strong></p>

<p><code>
$ ls -la /dev | grep nvidia
</code></p>

<p>You should see:</p>

<p><code>
crw-rw-rw-  1 root root    195,   0 Oct 25 19:37 nvidia0
crw-rw-rw-  1 root root    195, 255 Oct 25 19:37 nvidiactl
crw-rw-rw-  1 root root    251,   0 Oct 25 19:37 nvidia-uvm
</code></p>

<p>You&rsquo;ll have to adapt the <code>DOCKER_NVIDIA_DEVICES</code> variable below to match your particular devices.</p>

<p>Here&rsquo;s how to start the docker container:</p>

<p><code>
$ DOCKER_NVIDIA_DEVICES="--device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm"
$ sudo docker run -ti $DOCKER_NVIDIA_DEVICES tleyden5iwx/caffe-gpu /bin/bash
</code></p>

<p>It&rsquo;s a large docker image, so this might take a few minutes, depending on your network connection.</p>

<h2>Run caffe test suite</h2>

<p>After the above <code>docker run</code> command completes, your shell will now be inside a docker container that has Caffe installed.</p>

<p>You&rsquo;ll want run the Caffe test suite and make sure it passes.  This will validate your environment, including your GPU drivers.</p>

<p><code>
$ cd /opt/caffe
$ make test &amp;&amp; make runtest
</code></p>

<p><strong>Expected Result:</strong> <code>... [  PASSED  ] 838 tests.</code></p>

<h2>Run the MNIST LeNet example</h2>

<p>A more comprehensive way to verify your environment is to train the MNIST LeNet example:</p>

<p><code>
$ cd /opt/caffe/data/mnist
$ ./get_mnist.sh
$ cd /opt/caffe
$ ./examples/mnist/create_mnist.sh
$ ./examples/mnist/train_lenet.sh
</code></p>

<p>This will take a few minutes.</p>

<p><strong>Expected output:</strong></p>

<p><code>
libdc1394 error: Failed to initialize libdc1394
I1018 17:02:23.552733    66 caffe.cpp:90] Starting Optimization
I1018 17:02:23.553583    66 solver.cpp:32] Initializing solver from parameters:
... lots of output ...
I1018 17:17:58.684598    66 caffe.cpp:102] Optimization Done.
</code></p>

<p>Congratulations, you&rsquo;ve got GPU-powered Caffe running in a docker container &mdash; celebrate with a cup of <a href="http://www.yelp.com/biz/philz-coffee-berkeley-2">Philz</a>!</p>

<h1>References</h1>

<ul>
<li><a href="https://registry.hub.docker.com/u/tleyden5iwx/caffe-gpu">tleyden5iwx/caffe-gpu</a> Caffe Docker image (GPU)</li>
<li><a href="https://registry.hub.docker.com/u/tleyden5iwx/caffe">tleyden5iwx/caffe</a> Caffe Docker image (CPU-only)</li>
<li><a href="http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/">Docker on AWS GPU Ubuntu 14.04 / CUDA 6.5</a></li>
<li><a href="http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/">CUDA 6.5 on AWS GPU Instance Running Ubuntu 14.04</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CUDA 6.5 on AWS GPU instance running Ubuntu 14.04]]></title>
    <link href="http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/"/>
    <updated>2014-10-25T11:56:00-07:00</updated>
    <id>http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04</id>
    <content type="html"><![CDATA[<h2>Using a pre-built public AMI</h2>

<p>Based on the instructions in this blog post, I&rsquo;ve created an AMI and shared it publicly.  So the easiest thing to do is just use that pre-built AMI:</p>

<ul>
<li>Image: ami-2cbf3e44 (Ubuntu Server 14.04 LTS (HVM) &ndash; CUDA 6.5)</li>
<li>Instance type: g2.2xlarge</li>
<li>Storage: Use at least 8 GB, 20+ GB recommended</li>
</ul>


<p>If you use the pre-built AMI, then you can skip the rest of this article, since all of these steps are &ldquo;baked in&rdquo; to the AMI.</p>

<h2>Building from scratch</h2>

<p>Or if you prefer to build your own instance from scratch, keep reading.</p>

<p>Create a new EC2 instance:</p>

<ul>
<li>Image: ami-9eaa1cf6 (Ubuntu Server 14.04 LTS (HVM), SSD Volume Type)</li>
<li>Instance type: g2.2xlarge</li>
<li>Storage: Use at least 8 GB, 20+ GB recommended</li>
</ul>


<p>Install build-essential:</p>

<p><code>
$ apt-get update &amp;&amp; apt-get install build-essential
</code></p>

<p>Get CUDA installer:</p>

<p><code>
$ wget http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run
</code></p>

<p>Extract CUDA installer:</p>

<p><code>
$ chmod +x cuda_6.5.14_linux_64.run
$ mkdir nvidia_installers
$ ./cuda_6.5.14_linux_64.run -extract=`pwd`/nvidia_installers
</code></p>

<p>Run Nvidia driver installer:</p>

<p><code>
$ cd nvidia_installers
$ ./NVIDIA-Linux-x86_64-340.29.run
</code></p>

<p>At this point it will popup an 8-bit UI that will ask you to accept a license agreement, and then start installing.</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/install_cuda.png" alt="screenshot" /></p>

<p>At this point, I got an error:</p>

<p>```
Unable to load the kernel module &lsquo;nvidia.ko&rsquo;.  This happens most frequently when this kernel module was built against the wrong or</p>

<pre><code>     improperly configured kernel sources, with a version of gcc that differs from the one used to build the target kernel, or if a driver
     such as rivafb, nvidiafb, or nouveau is present and prevents the NVIDIA kernel module from obtaining ownership of the NVIDIA graphics
     device(s), or no NVIDIA GPU installed in this system is supported by this NVIDIA Linux graphics driver release.

     Please see the log entries 'Kernel module load error' and 'Kernel messages' at the end of the file '/var/log/nvidia-installer.log'
     for more information.
</code></pre>

<p>```</p>

<p>After <a href="https://devtalk.nvidia.com/default/topic/547588/error-installing-nvidia-drivers-on-x86_64-amazon-ec2-gpu-cluster-t20-gpu-/">reading this forum post</a> I installed:</p>

<p><code>
$ sudo apt-get install linux-image-extra-virtual
</code></p>

<p>When it prompted me what do to about the grub changes, I chose &ldquo;choose package maintainers version&rdquo;.</p>

<p>Reboot:</p>

<p><code>
$ reboot
</code></p>

<h2>Disable nouveau</h2>

<p>At this point you need to disable nouveau, since it conflicts with the nvidia kernel module.</p>

<p>Open a new file</p>

<p><code>
$ vi /etc/modprobe.d/blacklist-nouveau.conf
</code></p>

<p>and add these lines to it</p>

<p><code>
blacklist nouveau
blacklist lbm-nouveau
options nouveau modeset=0
alias nouveau off
alias lbm-nouveau off
</code></p>

<p>and then save the file.</p>

<p>Disable the Kernel Nouveau:</p>

<p><code>
$ echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf
</code></p>

<p>Reboot:</p>

<p><code>
$ update-initramfs -u
$ reboot
</code></p>

<h2>One more try &mdash; this time it works</h2>

<p>Get Kernel source:</p>

<p>```
$ apt-get install linux-source
$ apt-get install linux-headers-3.13.0-37-generic</p>

<p>```</p>

<p>Rerun Nvidia driver installer:</p>

<p><code>
$ cd nvidia_installers
$ ./NVIDIA-Linux-x86_64-340.29.run
</code></p>

<p>Load nvidia kernel module:</p>

<p><code>
$ modprobe nvidia
</code></p>

<p>Run CUDA + samples installer:</p>

<p><code>
$ ./cuda-linux64-rel-6.5.14-18749181.run
$ ./cuda-samples-linux-6.5.14-18745345.run
</code></p>

<h2>Verify CUDA is correctly installed</h2>

<p><code>
$ cd /usr/local/cuda/samples/1_Utilities/deviceQuery
$ make
$ ./deviceQuery   
</code></p>

<p>You should see the following output:</p>

<p><code>
deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 6.5, CUDA Runtime Version = 6.5, NumDevs = 1, Device0 = GRID K520
Result = PASS
</code></p>

<h2>References</h2>

<ul>
<li><a href="http://www.r-tutor.com/gpu-computing/cuda-installation/cuda6.5-ubuntu">http://www.r-tutor.com/gpu-computing/cuda-installation/cuda6.5-ubuntu</a></li>
<li><a href="http://askubuntu.com/questions/451672/installing-and-testing-cuda-in-ubuntu-14-04">http://askubuntu.com/questions/451672/installing-and-testing-cuda-in-ubuntu-14-04</a></li>
<li><a href="https://devtalk.nvidia.com/default/topic/547588/error-installing-nvidia-drivers-on-x86_64-amazon-ec2-gpu-cluster-t20-gpu-/">https://devtalk.nvidia.com/default/topic/547588/error-installing-nvidia-drivers-on-x86_64-amazon-ec2-gpu-cluster-t20-gpu-/</a></li>
<li><a href="https://devtalk.nvidia.com/default/topic/769719/drm-ko-missing-on-ubuntu-14-04-1-lts-aws-ec2-g2-2xlarge-instance/">https://devtalk.nvidia.com/default/topic/769719/drm-ko-missing-on-ubuntu-14-04-1-lts-aws-ec2-g2-2xlarge-instance/</a></li>
<li><a href="http://askubuntu.com/questions/451221/ubuntu-14-04-install-nvidia-driver">http://askubuntu.com/questions/451221/ubuntu-14-04-install-nvidia-driver</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
